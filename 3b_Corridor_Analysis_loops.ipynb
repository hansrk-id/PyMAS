{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b Corridor Analysis (loops)\n",
    "\n",
    "This module will produce plots of delay, speed, volume, and percent of good data at each loopgroup (using unsmoothed loopgroup data) as a function of time as well as along a corridor as a function of space. These plots can be used to diagnose the data quality both by comparing the actual loop data here with the plots from contour data to see if the data processing introduced errors and to compare the amount of delay calculated without aggregating across the year, as the contour data does. You can also look for discontinuities and messy/noisy data in each loop group that will help determine which data is reliable.\n",
    "\n",
    "The module also produces throughput plots both for diagnostic purposes and for publishing.\n",
    "\n",
    "The raw loop data needs to be downloaded from the Tracflow website and placed in the appropriate folder (default is *./[ccr]/1_Data/[region]/4_Loop Data/[year]*).\n",
    "\n",
    "This module also requires that the *3a_Corridor_Analysis* module has been completed and the Corridor object binary files are saved to an appropriate location (default is *./[ccr]/2_Corridor Output/[region]/*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "The inputs for this module are:\n",
    "\n",
    "Base Year, Current Year : the base and current analysis years for the current analysis. (e.g. 2015, 2017)\n",
    "\n",
    "CCR : the current CCR and name of the main folder for the current CCR (e.g. 'CCR 18')\n",
    "\n",
    "Analyst : analyst's name\n",
    "\n",
    "Suffix (in and out) : the *in* Suffix is the suffix for previously processed and written Corridor objects (either written with this module or the *3a_Corridor_Analysis* module). For example, to load Corridor objects *5 NWR_with_loops.dat* I would input *_with_loops* for the *in* Suffix.  \n",
    "The *out* Suffix is a tag to add to the filenames of the Excel and binary outputs of this module. For example, if Suffix = _8-20-2018 then the Excel outputfile for 5 NWR loopgroups would be named *5 NWR_thru_loops_8-20-2018.xlsx*.\n",
    "\n",
    "Update Plotting : this is a boolean (True/False) argument indicating whether to re-load the plot parameters (plot_params attribute of the Corridor objects, read from the *Plotting* sheet of the *[corridor]_[region]_config.xlsx* file.\n",
    "\n",
    "Percent Good Days : this is a threshold for the percent of good days of data that a loopgroup must have (both for base year and current year) to be plotted in png format. For example, if 40% is chosen (~ 100 good days) then all of the loopgroups in a given corridor with at least 40% of the days having good data will have the throughput plotted and output in png format (this is not for publication, just for data exploration).\n",
    "\n",
    "by_day Format : this is the format to output the diagnostic plots for each loopgroup containing percent of good days, delay, volume, and speed for each day in the base year and current year. Image formats (e.g. png) that open in Windows Photos are preferable because you can quickly scroll through the images and look for patterns.\n",
    "\n",
    "by_mp Format : this is the format to output the diagnostic plots for each corridor containing percent of good days, delay, volume, and speed at each loopgroup plotted by milepost. Since this is a large plot (especially for the longer corridors such as I-5 and I-405) it is helpful to plot this in pdf format so that it is clear and you can zoom in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------- import dependencies -----------------------------\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from pymas.corridor_tools import *\n",
    "from pymas.pymas_classes import Corridor, LoopGroup\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare loopgroup data\n",
    "\n",
    "These steps prepare the loopgroup data to be attached to the Corridor objects built in the 3a_Corridor_Analysis module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract loop files from .zip files\n",
    "\n",
    "Starting with the .zip files from TRAC, this cell will extract the loop .xlsx files and move the original zip files and accompanying plots (provided by TRAC) into subfolders in the *./[ccr]/1_Data/[region]/4_Loop Data/[year]/* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interface = '0_Interface.xlsx'\n",
    "sheet = 'Inputs'\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# You shouldn't need to edit anything below this line\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# get inputs from 0_Interface.xlsx \n",
    "inputs = get_inputs('3b', interface, sheet)\n",
    "base_year = inputs['base_year']\n",
    "curr_year = inputs['curr_year']\n",
    "ccr = inputs['ccr']\n",
    "\n",
    "reg_cors = get_batchlist()\n",
    "\n",
    "for reg, cor_list in reg_cors.iteritems():\n",
    "    print('\\nProcessing %s'%reg)\n",
    "    paths = define_paths(ccr, reg, base_year, curr_year)\n",
    "    \n",
    "    for cor in cor_list:\n",
    "        unzip_loops(cor, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build LoopGroups and write to .dat\n",
    "\n",
    "This is an optional (but highly recommended) step, which builds LoopGroup objects and writes them to binary files. The benefit to including this step is that if you need to rebuild corridor objects and call the add_loops function, it is much faster to add loops from the binary files produced by this cell than by re-building the LoopGroup objects from Excel files.\n",
    "\n",
    "**This is the most time-consuming and computationally demanding step in the entire PyMAS program. Expect it to take ~5 seconds per loop (for NWR, which has ~650 loops, this takes ~1 hour to complete). This is why it is helpful to run this optional step. Otherwise, re-building the loops from scratch if a Corridor object needs to be rebuilt will take a substantial amount of time, whereas adding pre-built loops to a Corridor object will only require a fraction of this time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interface = '0_Interface.xlsx'\n",
    "sheet = 'Inputs'\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# You shouldn't need to edit anything below this line\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# get inputs from 0_Interface.xlsx \n",
    "inputs = get_inputs('3b', interface, sheet)\n",
    "base_year = inputs['base_year']\n",
    "curr_year = inputs['curr_year']\n",
    "ccr = inputs['ccr']\n",
    "analyst = inputs['analyst']\n",
    "\n",
    "reg_cors = get_batchlist()\n",
    "\n",
    "for reg, cor_list in reg_cors.iteritems():\n",
    "    print('\\nProcessing %s'%reg)\n",
    "    \n",
    "    paths = define_paths(ccr, reg, base_year, curr_year)\n",
    "    p = os.path.join(paths['loop_path'])\n",
    "    \n",
    "    for cor in cor_list:\n",
    "        print('\\nProcessing %s %s'%(cor,reg))\n",
    "        for loop in get_loops(cor, paths):\n",
    "            print('Building %s LoopGroup object'%loop)\n",
    "            obj = LoopGroup(loop, base_year, curr_year, paths, analyst)\n",
    "            \n",
    "            with open(os.path.join(p, '%s.dat'%loop), 'wb') as f:\n",
    "                pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build objs dictionary\n",
    "\n",
    "This cell reads in Corridor objects that were written previously (either by the current module or by *3a_Corridor_Analysis*) and stores them in a dictionary called *objs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading NWR\n",
      "Loading 5 NWR_with_loops.dat Corridor object\n",
      "Loading 90 NWR_with_loops.dat Corridor object\n",
      "Loading 167 NWR_with_loops.dat Corridor object\n",
      "Loading 405 NWR_with_loops.dat Corridor object\n",
      "Loading 520 NWR_with_loops.dat Corridor object\n",
      "\n",
      "\n",
      "Done building objs dictionary\n"
     ]
    }
   ],
   "source": [
    "interface = '0_Interface.xlsx'\n",
    "sheet = 'Inputs'\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# You shouldn't need to edit anything below this line\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# get inputs from 0_Interface.xlsx \n",
    "inputs = get_inputs('3b', interface, sheet)\n",
    "base_year = inputs['base_year']\n",
    "curr_year = inputs['curr_year']\n",
    "ccr = inputs['ccr']\n",
    "analyst = inputs['analyst']\n",
    "suffix = inputs['suffix_in']\n",
    "\n",
    "reg_cors = get_batchlist()\n",
    "\n",
    "# Initialize empty dictionary\n",
    "objs = {}\n",
    "\n",
    "# loop through all regions\n",
    "for reg, cor_list in reg_cors.iteritems():\n",
    "    if len(cor_list) > 0:\n",
    "        print('\\nLoading %s'%(reg))\n",
    "        paths = define_paths(ccr, reg, base_year, curr_year)\n",
    "    \n",
    "    # loop through corridors and read into dictionary\n",
    "    for cor in cor_list:\n",
    "        name = '%s %s'%(cor, reg)\n",
    "        \n",
    "        print('Loading %s%s.dat Corridor object'%(name,suffix))\n",
    "        try:\n",
    "            objs[name] = read_object(name, 'Corridor', paths, suffix)\n",
    "        except IOError as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "print('\\n\\nDone building objs dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add loops\n",
    "\n",
    "This cell adds loop data to each Corridor object. As noted above, this step is much faster if the LoopGroup objects are already built and stored as .dat files in the *./[ccr]/1_Data/[region]/4_Loop Data/* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interface = '0_Interface.xlsx'\n",
    "sheet = 'Inputs'\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# You shouldn't need to edit anything below this line\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# get inputs from 0_Interface.xlsx \n",
    "inputs = get_inputs('3b', interface, sheet)\n",
    "base_year = inputs['base_year']\n",
    "curr_year = inputs['curr_year']\n",
    "ccr = inputs['ccr']\n",
    "analyst = inputs['analyst']\n",
    "suffix = inputs['suffix_in']\n",
    "\n",
    "\n",
    "reg_cors = get_batchlist()\n",
    "\n",
    "# loop through all regions\n",
    "for reg, cor_list in reg_cors.iteritems():\n",
    "    if len(cor_list) > 0:\n",
    "        print('\\nProcessing %s'%(reg))\n",
    "        paths = define_paths(ccr, reg, base_year, curr_year)\n",
    "    \n",
    "    # loop through corridors\n",
    "    for cor in cor_list:       \n",
    "        name = '%s %s'%(cor, reg)      \n",
    "        objs['%s %s'%(cor, reg)].add_loops()      \n",
    "\n",
    "print('\\n\\nDone adding loops')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write objects to .dat\n",
    "\n",
    "This cell writes the Corridor objects to .dat files. It is recommended to use a suffix here (in the *out* Suffix cell) so that this file doesn't overwrite the Corridor object written in *3a_Corridor_Analysis*. Subsequent steps, such as *4b_Commute_Analysis*, do not require the loop data to be included in the Corridor object. Therefore, it is much better to keep loop-less objects saved as *[corridor] [region].dat* so that when the objects are to be loaded into memory to have information extracted, a much smaller object needs to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interface = '0_Interface.xlsx'\n",
    "sheet = 'Inputs'\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# You shouldn't need to edit anything below this line\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# get inputs from 0_Interface.xlsx \n",
    "inputs = get_inputs('3b', interface, sheet)\n",
    "suffix = inputs['suffix_out']\n",
    "\n",
    "reg_cors = get_batchlist()\n",
    "\n",
    "# loop through all regions\n",
    "for reg, cor_list in reg_cors.iteritems():\n",
    "    \n",
    "    if len(cor_list) > 0:\n",
    "        print('\\nProcessing %s'%(reg))\n",
    "\n",
    "    # loop through corridors\n",
    "    for cor in cor_list:       \n",
    "        name = '%s %s'%(cor, reg)\n",
    "        print('Writing %s%s.dat'%(name, suffix))\n",
    "        \n",
    "        objs[name].export_dat(suffix)\n",
    "\n",
    "print('\\n\\nDone writing .dat files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loop data and export Loop Summary Excel file\n",
    "\n",
    "This cell generates plots from the loopgroup data. It plots throughput data in .png format for all loopgroups with at least the specified percentage of good days of data (*Percent Good Days* in input sheet) as well as in .pdf format for all loopgroups indicated in the *Plotting* sheet of the corridor config file. (The png files are to be used for data exploration, pdf for publication).\n",
    "\n",
    "It also produces an Excel file for each Corridor that includes the loop summary along the corridor (speed, volume, delay, number of good days) as well as throughput at each of the loopgroups that are plotted for publication (i.e. the loopgroups indicated in the *Plotting* sheet of the corridor config file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing NWR\n",
      "\n",
      "Plotting 5 NWR\n",
      "005es15792_MS__ is missing data for 2015\n",
      "005es16064_MS__ is missing data for 2015\n",
      "005es16640_MN__ is missing data for 2015\n",
      "005es16701_MS__ is missing data for 2015\n",
      "005es16885_MS__ is missing data for 2015\n",
      "005es17264_MS__ is missing data for 2015\n",
      "005es17826_MS__ is missing data for 2015\n",
      "\n",
      "Plotting 90 NWR\n",
      "090es00380_MW__ is missing data for 2015\n",
      "090es00390_ME__ is missing data for 2015\n",
      "090es00627_ME__ is missing data for 2015\n",
      "090es00627_MW__ is missing data for 2015\n",
      "090es00647_ME__ is missing data for 2015\n",
      "090es00647_MW__ is missing data for 2015\n",
      "090es01090_ME__ is missing data for 2017\n",
      "090es01864_MW__ is missing data for 2017\n",
      "\n",
      "Plotting 167 NWR\n",
      "167es01565_MN__ is missing data for 2015\n",
      "\n",
      "Plotting 405 NWR\n",
      "405es01536_MN__ is missing data for 2017\n",
      "405es01536_MS__ is missing data for 2017\n",
      "405es01577_MN__ is missing data for 2017\n",
      "405es01577_MS__ is missing data for 2017\n",
      "405es01686_MN__ is missing data for 2017\n",
      "405es01686_MS__ is missing data for 2017\n",
      "405es01724_MN__ is missing data for 2017\n",
      "405es01724_MS__ is missing data for 2017\n",
      "405es01746_MN__ is missing data for 2017\n",
      "405es01746_MS__ is missing data for 2017\n",
      "405es02097_MN__ is missing data for 2017\n",
      "405es02097_MS__ is missing data for 2017\n",
      "405es02250_MN__ is missing data for 2017\n",
      "405es02250_MS__ is missing data for 2017\n",
      "405es02272_MN__ is missing data for 2017\n",
      "405es02321_MN__ is missing data for 2017\n",
      "405es02462_MN__ is missing data for 2017\n",
      "405es02462_MS__ is missing data for 2017\n",
      "405es02553_MS__ is missing data for 2017\n",
      "405es02563_MN__ is missing data for 2017\n",
      "405es02665_MN__ is missing data for 2017\n",
      "405es02665_MS__ is missing data for 2017\n",
      "405es02687_MS__ is missing data for 2017\n",
      "405es02808_MN__ is missing data for 2017\n",
      "405es02808_MS__ is missing data for 2017\n",
      "405es02862_MN__ is missing data for 2017\n",
      "405es02862_MS__ is missing data for 2017\n",
      "405es02951_MN__ is missing data for 2017\n",
      "405es02951_MS__ is missing data for 2017\n",
      "\n",
      "Plotting 520 NWR\n",
      "520es00158_MW__ is missing data for 2017\n",
      "520es00160_MW__ is missing data for 2015\n",
      "520es00194_MW__ is missing data for 2015\n",
      "520es00197_ME__ is missing data for 2015\n",
      "520es00241_ME__ is missing data for 2015\n",
      "520es00241_MW__ is missing data for 2015\n",
      "520es00288_ME__ is missing data for 2015\n",
      "520es00288_MW__ is missing data for 2015\n",
      "520es00306_ME__ is missing data for 2017\n",
      "520es00306_MW__ is missing data for 2017\n",
      "520es00344_ME__ is missing data for 2015\n",
      "520es00344_MW__ is missing data for 2015\n",
      "520es00397_ME__ is missing data for 2017\n",
      "520es00397_MW__ is missing data for 2017\n",
      "520es00398_ME__ is missing data for 2015\n",
      "520es00398_MW__ is missing data for 2015\n",
      "520es00448_MW__ is missing data for 2015\n",
      "\n",
      "\n",
      "Done plotting.\n"
     ]
    }
   ],
   "source": [
    "interface = '0_Interface.xlsx'\n",
    "sheet = 'Inputs'\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# You shouldn't need to edit anything below this line\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# get inputs from 0_Interface.xlsx \n",
    "inputs = get_inputs('3b', interface, sheet)\n",
    "base_year = inputs['base_year']\n",
    "curr_year = inputs['curr_year']\n",
    "ccr = inputs['ccr']\n",
    "analyst = inputs['analyst']\n",
    "suffix = inputs['suffix_out']\n",
    "pctgd = inputs['pctgd']\n",
    "by_day_fmt = inputs['by_day_fmt']\n",
    "by_mp_fmt = inputs['by_mp_fmt']\n",
    "update = inputs['update_pp']\n",
    "\n",
    "reg_cors = get_batchlist()\n",
    "\n",
    "\n",
    "# loop through all regions\n",
    "for reg, cor_list in reg_cors.iteritems():\n",
    "\n",
    "    if len(cor_list) > 0:\n",
    "        print('\\nProcessing %s'%(reg))\n",
    "\n",
    "    # loop through corridors\n",
    "    for cor in cor_list:       \n",
    "        name = '%s %s'%(cor, reg)\n",
    "        \n",
    "        if name not in objs.keys():\n",
    "            print('%s Corridor object not in objs dictionary'%name)\n",
    "            continue\n",
    "        \n",
    "        print('\\nPlotting %s'%name)\n",
    "        \n",
    "        if update:\n",
    "            objs[name].update_plot_params()\n",
    "        \n",
    "        # plot throughput\n",
    "        objs[name].plot_throughput()    \n",
    "        objs[name].plot_throughput(lgs='config', fmt='pdf')\n",
    "        \n",
    "        # export Excel loop data\n",
    "        objs[name].export_excel_lg(suffix=suffix)\n",
    "        \n",
    "        # plot diagnostics\n",
    "        objs[name].plot_lg_data(by_mp_fmt=by_mp_fmt,\n",
    "                                by_day_fmt=by_day_fmt)     \n",
    "        \n",
    "print('\\n\\nDone plotting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
